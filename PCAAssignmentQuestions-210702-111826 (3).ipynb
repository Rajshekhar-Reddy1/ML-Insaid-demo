{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA Assignment (Questions).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kvpbUgMKgUbU"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>\n","\n","# **<center>PCA - Assignment Solution</center>**"]},{"cell_type":"markdown","metadata":{"id":"UW6GNJ2YWrWg"},"source":["---\n","# **Table of Contents**\n","---\n","\n","**1.** [**Introduction**](#Section1)<br>\n","**2.** [**Problem Statement**](#Section2)<br>\n","**3.** [**Instaling & Importing Libraries**](#Section3)<br>\n","  - **3.1** [**Installing Libraries**](#Section31)<br>\n","  - **3.2** [**Upgrading Libraries**](#Section32)<br>\n","  - **3.2** [**Importing Libraries**](#Section33)<br>\n","\n","**4.** [**Data Acquisition & Description**](#Section4)<br>\n","  - **4.1** [**Data Description**](#Section41)\n","  - **4.2** [**Data Information**](#Section42)\n","\n","**5.** [**Data Pre-Processing**](#Section6)<br>\n","  - **5.1** [**Data Pre-Profiling**](#Section51)<br>\n","  - **5.2** [**Data Cleaning**](#Section52)<br>\n","  - **5.3** [**Data Post-Profiling**](#Section53)<br>\n","\n","**6.** [**Exploratory Data Analysis**](#Section6)<br>\n","**7.** [**Data Post-Processing**](#Section7)<br>\n","  - **7.1** [**Feature Scaling**](#Section71)\n","  - **7.2** [**Data Splitting**](#Section72)\n","\n","**8.** [**Modelling Development & Evaluation without PCA**](#Section8)<br>\n","  - **8.1** [**Modelling, Prediction & Evaluation without PCA**](#Section81)<br>\n","  - **8.2** [**Dimensionality Reduction using PCA**](#Section82)<br>\n","  - **8.3** [**Modelling, Prediction & Evaluation with PCA**](#Section83)<br>\n","\n","**9.** [**Conclusion**](#section9)"]},{"cell_type":"markdown","metadata":{"id":"L-RITAh3OC5C"},"source":["---\n","<a name = Section1></a>\n","# **1. Introduction**\n","---\n","\n","- **Principal Component Analysis** helps with **dimensionality reduction** of **highly dimensional** datasets.\n","\n","- It is one of the most popular **linear dimension reduction** algorithms.\n","\n","- It is a **projection based method** that transforms the data by **projecting** it onto a **set of orthogonal** (perpendicular) **axes**.\n","\n","<center><img src=\"https://images3.programmersought.com/611/1d/1da21c4ce8bb7e0d68f27776d42a0c13.gif\" ></center>"]},{"cell_type":"markdown","metadata":{"id":"vDeC1MvbZymF"},"source":["---\n","<a name = Section2></a>\n","# **2. Problem Statement**\n","---\n","\n","- The need for **identifying breast cancer** in it's early stages has been increasing.\n","\n","- The **Wisconsin Diagnostic Laboratories** have a good record of diagnosing patients with cancer in their early stages.\n","\n","- But it is a time critical process to **generate**, **analyze** and **predict** if a particular **nucleus** can be **malignant or benign**.\n","\n","<center><img src=\"https://camo.githubusercontent.com/9f6c40f3ca523734a3b32aa166bbbc4527cc09df57113b3fb90b8768f1844d60/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f323630302f312a674e6346454c3163704770444334766f317a554157412e706e67\" width=70%></center>\n","\n","- They have hired you to help them **develop a predictor** that can predict if a **nucleus** can be **harmful** or not.\n","\n","- They have provided you with **dimensions** and other **concerned feautres** of the nucleus of **past patients** along with their results.\n","\n","- The **objective** is to **classify** if a patient can **potentially** suffer from **breast cancer or not**."]},{"cell_type":"markdown","metadata":{"id":"tP_PLqrtZ6h5"},"source":["---\n","<a name = Section3></a>\n","# **3. Installing & Importing Libraries**\n","---\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CxrjUfOi5Kor"},"source":["<a name = Section31></a>\n","### **3.1 Installing Libraries**"]},{"cell_type":"code","metadata":{"id":"G64l-tpL_G6c"},"source":["!pip install -q datascience                                         # Package that is required by pandas profiling\n","!pip install -q pandas-profiling                                    # Library to generate basic statistics about data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQ7MRLAo5N1V"},"source":["<a name = Section32></a>\n","### **3.2 Upgrading Libraries**\n","\n","- **After upgrading** the libraries, you need to **restart the runtime** to make the libraries in sync. \n","\n","- Make sure not to execute the cell above (3.1) and below (3.2) again after restarting the runtime."]},{"cell_type":"code","metadata":{"id":"B-Fik6Ur5Nu7"},"source":["!pip install -q --upgrade pandas-profiling\n","!pip install -q --upgrade yellowbrick"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3clrQtkRdfny"},"source":["<a name = Section33></a>\n","### **3.3 Importing Libraries**"]},{"cell_type":"code","metadata":{"id":"-KMSdBnRdeGN"},"source":["#-------------------------------------------------------------------------------------------------------------------------------\n","import pandas as pd                                                 # Importing for panel data analysis\n","from pandas_profiling import ProfileReport                          # Importing Pandas Profiling (To generate Univariate Analysis) \n","pd.set_option('display.max_columns', None)                          # Unfolding hidden features if the cardinality is high\n","pd.set_option('display.max_colwidth', None)                         # Unfolding the max feature width for better clearity\n","pd.set_option('display.max_rows', None)                             # Unfolding hidden data points if the cardinality is high\n","pd.set_option('mode.chained_assignment', None)                      # Removing restriction over chained assignments operations\n","pd.set_option('display.float_format', lambda x: '%.5f' % x)         # To suppress scientific notation over exponential values\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import numpy as np                                                  # Importing package numpys (For Numerical Python)\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import matplotlib.pyplot as plt                                     # Importing pyplot interface using matplotlib\n","import seaborn as sns                                               # Importin seaborm library for interactive visualization\n","%matplotlib inline\n","#-------------------------------------------------------------------------------------------------------------------------------\n","from sklearn.preprocessing import StandardScaler                    # To import a standard scaler for scaling the features\n","from sklearn.model_selection import train_test_split                # To split the data into train and test datasets\n","from sklearn.ensemble import RandomForestClassifier                 # To instantiate a random forest classifier\n","from sklearn.linear_model import LogisticRegression                 # To instantiate a logistic regression classifier\n","from sklearn.metrics import accuracy_score                          # To calculate the accuracy score of the classifiers\n","from sklearn.decomposition import PCA                               # To instantiate Principal Component Analysis\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import warnings                                                     # Importing warning to disable runtime warnings\n","warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NoTfMQ26Ucbg"},"source":["---\n","<a name = Section4></a>\n","# **4. Data Acquisition & Description**\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"WaAN48TFm7S8"},"source":["- The features in the dataset are computed from a **digitized image** of a **fine needle aspirate** (FNA) of a breast mass.\n","- They describe **characteristics** of the **cell nuclei** present in the image.\n","\n","| Records | Features | Dataset Size |\n","| :-- | :-- | :-- |\n","| 569 | 33 | 122 KB| \n","\n","- The dataset has **ten real-valued features** that are computed for each **cell nucleus**:\n","\n","  - a) **radius** (mean of distances from center to points on the perimeter)\n","  - b) **texture** (standard deviation of gray-scale values)\n","  - c) **perimeter**\n","  - d) **area**\n","  - e) **smoothness** (local variation in radius lengths)\n","  - f) **compactness** (perimeter^2 / area - 1.0)\n","  - g) **concavity** (severity of concave portions of the contour)\n","  - h) **concave points** (number of concave portions of the contour)\n","  - i) **symmetry**\n","  - j) **fractal dimension** (\"coastline approximation\" - 1)\n","\n","- The **mean**, **standard error** and \"**worst**\" or **largest** (mean of the three largest values) of these features were computed for each image, resulting in 30 features.\n","\n","- For instance, **field 3 is Mean Radius**, **field 13 is Radius SE**, **field 23 is Worst Radius**.\n","\n","| Id | Feature | Description |\n","| :-- | :--| :--|\n","|01|id|ID number|\n","|02|diagnosis|Diagnosis (M = malignant, B = benign)|\n","|03|radius_mean|Mean radius|\n","|04|texture_mean|Mean texture|\n","|05|perimeter_mean|Mean perimeter|\n","|06|area_mean|Mean Area|\n","|07|smoothness_mean|Mean Smoothness|\n","|08|compactness_mean|Mean Compactness|\n","|09|concavity_mean|Mean Concavity|\n","|10|concave_points_mean|Mean number of concave portions|\n","|11|symmetry_mean|Mean Symmetry|\n","|12|fractal_dimension_mean|Mean Fractal Dimension|\n","|13|radius_se|Standard Error of Radius|\n","|14|texture_se|Standard Error of texture|\n","|15|perimeter_se|Standard Error of Perimeter|\n","|16|area_se|Standard Error of Area|\n","|17|smoothness_se|Standard Error of Smoothness|\n","|18|compactness_se|Standard Error of Compactness|\n","|19|concavity_se|Standard Error of Concavity|\n","|20|concave_points_se|Standard Error of number of concave portions|\n","|21|symmetry_se|Standard Error of Symmetry|\n","|22|fractal_dimension_se|Standard Error of Fractal dimension|\n","|23|radius_worst|Worst/Largest radius measured|\n","|24|texture_worst|Worst/Largest texture measured|\n","|25|perimeter_worst|Worst/Largest perimeter measured|\n","|26|area_worst|Worst/Largest area measured|\n","|27|smoothness_worst|Worst/Largest smoothness measured|\n","|28|compactness_worst|Worst/Largest compactness measured|\n","|29|concavity_worst|Worst/Largest concavity measured|\n","|30|concave_points_worst|Highest no. of concave portions measured|\n","|31|symmetry_worst|Worst/Largest symmetry measured|\n","|32|fractal_dimension_worst|Worst/Largest Fractal dimension measured|\n","|33|Unnamed: 32|Unknown|\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"id":"9mbDdkfRWule","executionInfo":{"status":"ok","timestamp":1625052050289,"user_tz":-330,"elapsed":38,"user":{"displayName":"Hiren Rupchandani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgU4n1VRWoxNACyzwiLFFnL3xL6qH1xJchHFekUbI=s64","userId":"16888644812809569435"}},"outputId":"07128dbc-d021-47cd-9959-1b3401d2654e"},"source":["cancer = pd.read_csv(filepath_or_buffer=\"https://raw.githubusercontent.com/insaid2018/Term-3/master/Data/Assignment/cancer.csv\")\n","print('Shape of the dataset:', cancer.shape)\n","cancer.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of the dataset: (569, 33)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>fractal_dimension_mean</th>\n","      <th>radius_se</th>\n","      <th>texture_se</th>\n","      <th>perimeter_se</th>\n","      <th>area_se</th>\n","      <th>smoothness_se</th>\n","      <th>compactness_se</th>\n","      <th>concavity_se</th>\n","      <th>concave points_se</th>\n","      <th>symmetry_se</th>\n","      <th>fractal_dimension_se</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","      <th>Unnamed: 32</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>M</td>\n","      <td>17.99000</td>\n","      <td>10.38000</td>\n","      <td>122.80000</td>\n","      <td>1001.00000</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.24190</td>\n","      <td>0.07871</td>\n","      <td>1.09500</td>\n","      <td>0.90530</td>\n","      <td>8.58900</td>\n","      <td>153.40000</td>\n","      <td>0.00640</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.00619</td>\n","      <td>25.38000</td>\n","      <td>17.33000</td>\n","      <td>184.60000</td>\n","      <td>2019.00000</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.71190</td>\n","      <td>0.26540</td>\n","      <td>0.46010</td>\n","      <td>0.11890</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>M</td>\n","      <td>20.57000</td>\n","      <td>17.77000</td>\n","      <td>132.90000</td>\n","      <td>1326.00000</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.18120</td>\n","      <td>0.05667</td>\n","      <td>0.54350</td>\n","      <td>0.73390</td>\n","      <td>3.39800</td>\n","      <td>74.08000</td>\n","      <td>0.00522</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.00353</td>\n","      <td>24.99000</td>\n","      <td>23.41000</td>\n","      <td>158.80000</td>\n","      <td>1956.00000</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.24160</td>\n","      <td>0.18600</td>\n","      <td>0.27500</td>\n","      <td>0.08902</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>M</td>\n","      <td>19.69000</td>\n","      <td>21.25000</td>\n","      <td>130.00000</td>\n","      <td>1203.00000</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.20690</td>\n","      <td>0.05999</td>\n","      <td>0.74560</td>\n","      <td>0.78690</td>\n","      <td>4.58500</td>\n","      <td>94.03000</td>\n","      <td>0.00615</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.00457</td>\n","      <td>23.57000</td>\n","      <td>25.53000</td>\n","      <td>152.50000</td>\n","      <td>1709.00000</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.45040</td>\n","      <td>0.24300</td>\n","      <td>0.36130</td>\n","      <td>0.08758</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>M</td>\n","      <td>11.42000</td>\n","      <td>20.38000</td>\n","      <td>77.58000</td>\n","      <td>386.10000</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.25970</td>\n","      <td>0.09744</td>\n","      <td>0.49560</td>\n","      <td>1.15600</td>\n","      <td>3.44500</td>\n","      <td>27.23000</td>\n","      <td>0.00911</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.00921</td>\n","      <td>14.91000</td>\n","      <td>26.50000</td>\n","      <td>98.87000</td>\n","      <td>567.70000</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.68690</td>\n","      <td>0.25750</td>\n","      <td>0.66380</td>\n","      <td>0.17300</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>M</td>\n","      <td>20.29000</td>\n","      <td>14.34000</td>\n","      <td>135.10000</td>\n","      <td>1297.00000</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.18090</td>\n","      <td>0.05883</td>\n","      <td>0.75720</td>\n","      <td>0.78130</td>\n","      <td>5.43800</td>\n","      <td>94.44000</td>\n","      <td>0.01149</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.00511</td>\n","      <td>22.54000</td>\n","      <td>16.67000</td>\n","      <td>152.20000</td>\n","      <td>1575.00000</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.40000</td>\n","      <td>0.16250</td>\n","      <td>0.23640</td>\n","      <td>0.07678</td>\n","      <td>nan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n","0    842302         M     17.99000      10.38000       122.80000 1001.00000   \n","1    842517         M     20.57000      17.77000       132.90000 1326.00000   \n","2  84300903         M     19.69000      21.25000       130.00000 1203.00000   \n","3  84348301         M     11.42000      20.38000        77.58000  386.10000   \n","4  84358402         M     20.29000      14.34000       135.10000 1297.00000   \n","\n","   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n","0          0.11840           0.27760         0.30010              0.14710   \n","1          0.08474           0.07864         0.08690              0.07017   \n","2          0.10960           0.15990         0.19740              0.12790   \n","3          0.14250           0.28390         0.24140              0.10520   \n","4          0.10030           0.13280         0.19800              0.10430   \n","\n","   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n","0        0.24190                 0.07871    1.09500     0.90530       8.58900   \n","1        0.18120                 0.05667    0.54350     0.73390       3.39800   \n","2        0.20690                 0.05999    0.74560     0.78690       4.58500   \n","3        0.25970                 0.09744    0.49560     1.15600       3.44500   \n","4        0.18090                 0.05883    0.75720     0.78130       5.43800   \n","\n","    area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n","0 153.40000        0.00640         0.04904       0.05373            0.01587   \n","1  74.08000        0.00522         0.01308       0.01860            0.01340   \n","2  94.03000        0.00615         0.04006       0.03832            0.02058   \n","3  27.23000        0.00911         0.07458       0.05661            0.01867   \n","4  94.44000        0.01149         0.02461       0.05688            0.01885   \n","\n","   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n","0      0.03003               0.00619      25.38000       17.33000   \n","1      0.01389               0.00353      24.99000       23.41000   \n","2      0.02250               0.00457      23.57000       25.53000   \n","3      0.05963               0.00921      14.91000       26.50000   \n","4      0.01756               0.00511      22.54000       16.67000   \n","\n","   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n","0        184.60000  2019.00000           0.16220            0.66560   \n","1        158.80000  1956.00000           0.12380            0.18660   \n","2        152.50000  1709.00000           0.14440            0.42450   \n","3         98.87000   567.70000           0.20980            0.86630   \n","4        152.20000  1575.00000           0.13740            0.20500   \n","\n","   concavity_worst  concave points_worst  symmetry_worst  \\\n","0          0.71190               0.26540         0.46010   \n","1          0.24160               0.18600         0.27500   \n","2          0.45040               0.24300         0.36130   \n","3          0.68690               0.25750         0.66380   \n","4          0.40000               0.16250         0.23640   \n","\n","   fractal_dimension_worst  Unnamed: 32  \n","0                  0.11890          nan  \n","1                  0.08902          nan  \n","2                  0.08758          nan  \n","3                  0.17300          nan  \n","4                  0.07678          nan  "]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"JO2fzBTicyoS"},"source":["<a name = Section41></a>\n","### **4.1 Data Description**\n","\n","- In this section we will get **information about the data** and see some observations."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"he4Y7ZlhdPBD","executionInfo":{"status":"ok","timestamp":1625052050734,"user_tz":-330,"elapsed":463,"user":{"displayName":"Hiren Rupchandani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgU4n1VRWoxNACyzwiLFFnL3xL6qH1xJchHFekUbI=s64","userId":"16888644812809569435"}},"outputId":"d3a2fd9c-15e2-427e-c123-308934e55372"},"source":["cancer.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>fractal_dimension_mean</th>\n","      <th>radius_se</th>\n","      <th>texture_se</th>\n","      <th>perimeter_se</th>\n","      <th>area_se</th>\n","      <th>smoothness_se</th>\n","      <th>compactness_se</th>\n","      <th>concavity_se</th>\n","      <th>concave points_se</th>\n","      <th>symmetry_se</th>\n","      <th>fractal_dimension_se</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","      <th>Unnamed: 32</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>569.00000</td>\n","      <td>0.00000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>30371831.43234</td>\n","      <td>14.12729</td>\n","      <td>19.28965</td>\n","      <td>91.96903</td>\n","      <td>654.88910</td>\n","      <td>0.09636</td>\n","      <td>0.10434</td>\n","      <td>0.08880</td>\n","      <td>0.04892</td>\n","      <td>0.18116</td>\n","      <td>0.06280</td>\n","      <td>0.40517</td>\n","      <td>1.21685</td>\n","      <td>2.86606</td>\n","      <td>40.33708</td>\n","      <td>0.00704</td>\n","      <td>0.02548</td>\n","      <td>0.03189</td>\n","      <td>0.01180</td>\n","      <td>0.02054</td>\n","      <td>0.00379</td>\n","      <td>16.26919</td>\n","      <td>25.67722</td>\n","      <td>107.26121</td>\n","      <td>880.58313</td>\n","      <td>0.13237</td>\n","      <td>0.25427</td>\n","      <td>0.27219</td>\n","      <td>0.11461</td>\n","      <td>0.29008</td>\n","      <td>0.08395</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>125020585.61222</td>\n","      <td>3.52405</td>\n","      <td>4.30104</td>\n","      <td>24.29898</td>\n","      <td>351.91413</td>\n","      <td>0.01406</td>\n","      <td>0.05281</td>\n","      <td>0.07972</td>\n","      <td>0.03880</td>\n","      <td>0.02741</td>\n","      <td>0.00706</td>\n","      <td>0.27731</td>\n","      <td>0.55165</td>\n","      <td>2.02185</td>\n","      <td>45.49101</td>\n","      <td>0.00300</td>\n","      <td>0.01791</td>\n","      <td>0.03019</td>\n","      <td>0.00617</td>\n","      <td>0.00827</td>\n","      <td>0.00265</td>\n","      <td>4.83324</td>\n","      <td>6.14626</td>\n","      <td>33.60254</td>\n","      <td>569.35699</td>\n","      <td>0.02283</td>\n","      <td>0.15734</td>\n","      <td>0.20862</td>\n","      <td>0.06573</td>\n","      <td>0.06187</td>\n","      <td>0.01806</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>8670.00000</td>\n","      <td>6.98100</td>\n","      <td>9.71000</td>\n","      <td>43.79000</td>\n","      <td>143.50000</td>\n","      <td>0.05263</td>\n","      <td>0.01938</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.10600</td>\n","      <td>0.04996</td>\n","      <td>0.11150</td>\n","      <td>0.36020</td>\n","      <td>0.75700</td>\n","      <td>6.80200</td>\n","      <td>0.00171</td>\n","      <td>0.00225</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00788</td>\n","      <td>0.00089</td>\n","      <td>7.93000</td>\n","      <td>12.02000</td>\n","      <td>50.41000</td>\n","      <td>185.20000</td>\n","      <td>0.07117</td>\n","      <td>0.02729</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.15650</td>\n","      <td>0.05504</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>869218.00000</td>\n","      <td>11.70000</td>\n","      <td>16.17000</td>\n","      <td>75.17000</td>\n","      <td>420.30000</td>\n","      <td>0.08637</td>\n","      <td>0.06492</td>\n","      <td>0.02956</td>\n","      <td>0.02031</td>\n","      <td>0.16190</td>\n","      <td>0.05770</td>\n","      <td>0.23240</td>\n","      <td>0.83390</td>\n","      <td>1.60600</td>\n","      <td>17.85000</td>\n","      <td>0.00517</td>\n","      <td>0.01308</td>\n","      <td>0.01509</td>\n","      <td>0.00764</td>\n","      <td>0.01516</td>\n","      <td>0.00225</td>\n","      <td>13.01000</td>\n","      <td>21.08000</td>\n","      <td>84.11000</td>\n","      <td>515.30000</td>\n","      <td>0.11660</td>\n","      <td>0.14720</td>\n","      <td>0.11450</td>\n","      <td>0.06493</td>\n","      <td>0.25040</td>\n","      <td>0.07146</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>906024.00000</td>\n","      <td>13.37000</td>\n","      <td>18.84000</td>\n","      <td>86.24000</td>\n","      <td>551.10000</td>\n","      <td>0.09587</td>\n","      <td>0.09263</td>\n","      <td>0.06154</td>\n","      <td>0.03350</td>\n","      <td>0.17920</td>\n","      <td>0.06154</td>\n","      <td>0.32420</td>\n","      <td>1.10800</td>\n","      <td>2.28700</td>\n","      <td>24.53000</td>\n","      <td>0.00638</td>\n","      <td>0.02045</td>\n","      <td>0.02589</td>\n","      <td>0.01093</td>\n","      <td>0.01873</td>\n","      <td>0.00319</td>\n","      <td>14.97000</td>\n","      <td>25.41000</td>\n","      <td>97.66000</td>\n","      <td>686.50000</td>\n","      <td>0.13130</td>\n","      <td>0.21190</td>\n","      <td>0.22670</td>\n","      <td>0.09993</td>\n","      <td>0.28220</td>\n","      <td>0.08004</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>8813129.00000</td>\n","      <td>15.78000</td>\n","      <td>21.80000</td>\n","      <td>104.10000</td>\n","      <td>782.70000</td>\n","      <td>0.10530</td>\n","      <td>0.13040</td>\n","      <td>0.13070</td>\n","      <td>0.07400</td>\n","      <td>0.19570</td>\n","      <td>0.06612</td>\n","      <td>0.47890</td>\n","      <td>1.47400</td>\n","      <td>3.35700</td>\n","      <td>45.19000</td>\n","      <td>0.00815</td>\n","      <td>0.03245</td>\n","      <td>0.04205</td>\n","      <td>0.01471</td>\n","      <td>0.02348</td>\n","      <td>0.00456</td>\n","      <td>18.79000</td>\n","      <td>29.72000</td>\n","      <td>125.40000</td>\n","      <td>1084.00000</td>\n","      <td>0.14600</td>\n","      <td>0.33910</td>\n","      <td>0.38290</td>\n","      <td>0.16140</td>\n","      <td>0.31790</td>\n","      <td>0.09208</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>911320502.00000</td>\n","      <td>28.11000</td>\n","      <td>39.28000</td>\n","      <td>188.50000</td>\n","      <td>2501.00000</td>\n","      <td>0.16340</td>\n","      <td>0.34540</td>\n","      <td>0.42680</td>\n","      <td>0.20120</td>\n","      <td>0.30400</td>\n","      <td>0.09744</td>\n","      <td>2.87300</td>\n","      <td>4.88500</td>\n","      <td>21.98000</td>\n","      <td>542.20000</td>\n","      <td>0.03113</td>\n","      <td>0.13540</td>\n","      <td>0.39600</td>\n","      <td>0.05279</td>\n","      <td>0.07895</td>\n","      <td>0.02984</td>\n","      <td>36.04000</td>\n","      <td>49.54000</td>\n","      <td>251.20000</td>\n","      <td>4254.00000</td>\n","      <td>0.22260</td>\n","      <td>1.05800</td>\n","      <td>1.25200</td>\n","      <td>0.29100</td>\n","      <td>0.66380</td>\n","      <td>0.20750</td>\n","      <td>nan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n","count       569.00000    569.00000     569.00000       569.00000  569.00000   \n","mean   30371831.43234     14.12729      19.28965        91.96903  654.88910   \n","std   125020585.61222      3.52405       4.30104        24.29898  351.91413   \n","min        8670.00000      6.98100       9.71000        43.79000  143.50000   \n","25%      869218.00000     11.70000      16.17000        75.17000  420.30000   \n","50%      906024.00000     13.37000      18.84000        86.24000  551.10000   \n","75%     8813129.00000     15.78000      21.80000       104.10000  782.70000   \n","max   911320502.00000     28.11000      39.28000       188.50000 2501.00000   \n","\n","       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n","count        569.00000         569.00000       569.00000            569.00000   \n","mean           0.09636           0.10434         0.08880              0.04892   \n","std            0.01406           0.05281         0.07972              0.03880   \n","min            0.05263           0.01938         0.00000              0.00000   \n","25%            0.08637           0.06492         0.02956              0.02031   \n","50%            0.09587           0.09263         0.06154              0.03350   \n","75%            0.10530           0.13040         0.13070              0.07400   \n","max            0.16340           0.34540         0.42680              0.20120   \n","\n","       symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n","count      569.00000               569.00000  569.00000   569.00000   \n","mean         0.18116                 0.06280    0.40517     1.21685   \n","std          0.02741                 0.00706    0.27731     0.55165   \n","min          0.10600                 0.04996    0.11150     0.36020   \n","25%          0.16190                 0.05770    0.23240     0.83390   \n","50%          0.17920                 0.06154    0.32420     1.10800   \n","75%          0.19570                 0.06612    0.47890     1.47400   \n","max          0.30400                 0.09744    2.87300     4.88500   \n","\n","       perimeter_se   area_se  smoothness_se  compactness_se  concavity_se  \\\n","count     569.00000 569.00000      569.00000       569.00000     569.00000   \n","mean        2.86606  40.33708        0.00704         0.02548       0.03189   \n","std         2.02185  45.49101        0.00300         0.01791       0.03019   \n","min         0.75700   6.80200        0.00171         0.00225       0.00000   \n","25%         1.60600  17.85000        0.00517         0.01308       0.01509   \n","50%         2.28700  24.53000        0.00638         0.02045       0.02589   \n","75%         3.35700  45.19000        0.00815         0.03245       0.04205   \n","max        21.98000 542.20000        0.03113         0.13540       0.39600   \n","\n","       concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n","count          569.00000    569.00000             569.00000     569.00000   \n","mean             0.01180      0.02054               0.00379      16.26919   \n","std              0.00617      0.00827               0.00265       4.83324   \n","min              0.00000      0.00788               0.00089       7.93000   \n","25%              0.00764      0.01516               0.00225      13.01000   \n","50%              0.01093      0.01873               0.00319      14.97000   \n","75%              0.01471      0.02348               0.00456      18.79000   \n","max              0.05279      0.07895               0.02984      36.04000   \n","\n","       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n","count      569.00000        569.00000   569.00000         569.00000   \n","mean        25.67722        107.26121   880.58313           0.13237   \n","std          6.14626         33.60254   569.35699           0.02283   \n","min         12.02000         50.41000   185.20000           0.07117   \n","25%         21.08000         84.11000   515.30000           0.11660   \n","50%         25.41000         97.66000   686.50000           0.13130   \n","75%         29.72000        125.40000  1084.00000           0.14600   \n","max         49.54000        251.20000  4254.00000           0.22260   \n","\n","       compactness_worst  concavity_worst  concave points_worst  \\\n","count          569.00000        569.00000             569.00000   \n","mean             0.25427          0.27219               0.11461   \n","std              0.15734          0.20862               0.06573   \n","min              0.02729          0.00000               0.00000   \n","25%              0.14720          0.11450               0.06493   \n","50%              0.21190          0.22670               0.09993   \n","75%              0.33910          0.38290               0.16140   \n","max              1.05800          1.25200               0.29100   \n","\n","       symmetry_worst  fractal_dimension_worst  Unnamed: 32  \n","count       569.00000                569.00000      0.00000  \n","mean          0.29008                  0.08395          nan  \n","std           0.06187                  0.01806          nan  \n","min           0.15650                  0.05504          nan  \n","25%           0.25040                  0.07146          nan  \n","50%           0.28220                  0.08004          nan  \n","75%           0.31790                  0.09208          nan  \n","max           0.66380                  0.20750          nan  "]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"H1mLyxIadtYX"},"source":["**Observations**:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dGmO_XdjfEPE"},"source":["<a name = Section42></a>\n","### **4.2 Data Information**\n","\n","- In this section we will see the **information about the types of features**."]},{"cell_type":"code","metadata":{"id":"euTyCsj9fJqo"},"source":["cancer.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d83elwXbfI7s"},"source":["**Observations**:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pgxQNOG4L2Lw"},"source":["<a name = Section51></a>\n","\n","---\n","# **5. Data Pre-Processing**\n","---"]},{"cell_type":"markdown","metadata":{"id":"kFY8dGhhgTW1"},"source":["<a name = Section51></a>\n","\n","### **5.1 Data Pre-Profiling**\n"," \n","- For **quick analysis** pandas profiling is very handy.\n","\n","- Generates profile reports from a pandas DataFrame.\n","\n","- For each column **statistics** are presented in an interactive HTML report."]},{"cell_type":"code","metadata":{"id":"yNn1xkaRC6o5"},"source":["# profile = ProfileReport(df=cancer)\n","# profile.to_file(output_file='Pre Profiling Report.html')\n","# print('Accomplished!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xFDjxklrDf28"},"source":["**Observations**:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GbNNv855gFHE"},"source":["<a name = Section52></a>\n","\n","#### **Performing Operations**\n"]},{"cell_type":"markdown","metadata":{"id":"AF2zeQreMiZ4"},"source":["---\n","**<h4>Question 1**: Write a function to delete the column having missing values present in the dataset.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can use the `.replace()` method to replace the zeros with the median value.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"6L3yUQw2Ncqy"},"source":["def delete_cancer(data=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MoNBqw11AZt"},"source":["delete_cancer(data=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4mqQzRa1UTFI"},"source":["**Observations:**\n"]},{"cell_type":"markdown","metadata":{"id":"MmLDSEruPD_7"},"source":["---\n","**<h4>Question 2**: Write a function to convert the diagnosis feature values (B or M) into binary values (0 or 1) using the map method.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Convert M into 1 and B into 0 using `data['diagnosis'].map()` method\n","\n","</details>\n","\n"]},{"cell_type":"code","metadata":{"id":"_FtmPEigOVO-"},"source":["def convert_diagnosis(data=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"le8ydIsG0-4o"},"source":["convert_diagnosis(data=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miIEexuZQmH1"},"source":["<a name = Section52></a>\n","\n","### **5.2 Data Post-Profiling**"]},{"cell_type":"code","metadata":{"id":"1sHiZ0HcQmH6"},"source":["# profile = ProfileReport(df=cancer)\n","# profile.to_file(output_file='Post Profiling Report.html')\n","# print('Accomplished!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANjvqSc-Qvhv"},"source":["**Observations**:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BYKMQCO3QvzY"},"source":["<a name = Section6></a>\n","\n","---\n","# **6. Exploratory Data Analysis**\n","---"]},{"cell_type":"markdown","metadata":{"id":"PIRsR_4pQ7uQ"},"source":["---\n","**<h4>Question 3**:Create a function that checks the count and proportion of the diagnosis feature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create a 10x7 inches figure.\n","\n","- Use `sns.countplot()` on the `'diagnosis'` feature.\n","\n","- Add proportion to the bars.\n","\n","- Add additional cosmetics like `grid` and `title`.\n","\n","- Set `fontsize` for ticks as 12, labels as 14 and title as 16.\n","\n","- Use `plt.show()` to properly display the plot.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"pEPB3dZRQvzZ"},"source":["def diagnosis_checker(data=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"apZM2TYy09FX"},"source":["diagnosis_checker(data=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wbiXMf6PPjnt"},"source":["**Observations:**"]},{"cell_type":"markdown","metadata":{"id":"p6atlci7kWPd"},"source":["---\n","**<h4>Question 4**: Create a function that plots a displot for any of the independent features concerning diagnosis.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use `sns.displot()` with **x** parameter as any **feature name** and **hue** as **diagnosis** feature.\n","\n","- Keep `aspect` of the displot as 3.\n","\n","- Keep `kde=True`.\n","\n","- Add additional cosmetics like `grid` and `title`.\n","\n","- Set `fontsize` for ticks as 12, labels as 14 and title as 16.\n","\n","- Use `plt.show()` to properly display the plot.\n","\n","</details>\n","\n"]},{"cell_type":"code","metadata":{"id":"eUm2jWXPcp9D"},"source":["def make_displot(data=None, column=None):\n","    # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMQ1l9ju07J_"},"source":["make_displot(data=None, column=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Z1ZMAf_yUij"},"source":["**Observations:**"]},{"cell_type":"markdown","metadata":{"id":"02PMmfKIkw32"},"source":["---\n","**<h4>Question 5**: Create a function that plots a scatterplot between any two independent features concerning diagnosis feature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create a 10x10 inches figure.\n","\n","- Use `sns.scatterplot()` with **x** parameter as any **feature**, **y** parameter as any other **feature**, and **hue** as **diagnosis** feature.\n","\n","- Add additional cosmetics like `grid` and `title`.\n","\n","- Set `fontsize` for ticks as 12, labels as 14 and title as 16.\n","\n","- Use `plt.show()` to properly display the plot.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"A0N_ofW-gtOf"},"source":["def make_scatter(data=None, column_x=None, column_y=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQeu9ePj05eA"},"source":["make_scatter(data=None, column_x=None, column_y=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ey4nx5ArUAsg"},"source":["**Observations:**"]},{"cell_type":"markdown","metadata":{"id":"AixaugCodU-n"},"source":["<a name = Section7></a>\n","\n","---\n","# **7. Data Post-Processing**\n","---"]},{"cell_type":"markdown","metadata":{"id":"n5G0BF7_dOb3"},"source":["<a name = Section71></a>\n","\n","### **7.1 Feature Scaling**\n","\n","- In this section, we will perform standard scaling over the input features."]},{"cell_type":"markdown","metadata":{"id":"Xg-1Lxo1nT0a"},"source":["---\n","**<h4>Question 6**: Create a function that extracts the dependent and the independent variables into dataframes X and y.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create input dataframe X by dropping only \"diagnosis\" feature from axis 1.\n","\n","- Create target series by using \"diagnosis\" as value.\n","\n","</details>\n","\n"]},{"cell_type":"code","metadata":{"id":"ATpAvrnynfkE"},"source":["def feature_extract(data=None):\n","    # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eG7VUH0a02-P"},"source":["feature_extract(data=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2LUe_xygRiR"},"source":["\n","---\n","**<h4>Question 7**: Create a function that uses StandardScaler on X dataframe.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Instantiate a scaler object using StandardScaler().\n","\n","- Fit and transform input features (X) using `.fit_transform(X)` method.\n","\n","- Create a dataframe using the output from .fit_transform() along with the feature names of input dataframe (X).\n","\n","</details>\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"a_BEqwvTgRiS"},"source":["def scale_data(X=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MeYBf3EH01QY"},"source":["scale_data(X=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t0hQw53rdnvv"},"source":["<a name = Section72></a>\n","\n","### **7.2 Data Preparation**\n","\n","- Now we will **split** our **data** in **training** and **testing** part for further development."]},{"cell_type":"markdown","metadata":{"id":"UZo2q50spg1A"},"source":["---\n","**<h4>Question 8**: Create a function that splits X and y into train and test dataset.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use `.train_test_split()` method to split the dataset.\n","\n","- Use `test_size` = **0.25** and `random_state` = **42**.\n","\n","- **Stratify** the target variable.\n","\n","</details>\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"qego7xSQp_Om"},"source":["def data_split(X=None, y=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtoM4QZx0yG8"},"source":["data_split(X=None, y=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oz0wFNUEd_ox"},"source":["<a name = Section8></a>\n","\n","---\n","# **8. Modelling Development & Evaluation**\n","---"]},{"cell_type":"markdown","metadata":{"id":"hzcIXXK6YQ6g"},"source":["<a name = Section81></a>\n","\n","### **8.1 Modelling Development & Evaluation without PCA**\n","\n","- In this section, we will develop some baseline models using the train and test set."]},{"cell_type":"markdown","metadata":{"id":"Jqm0ograshoX"},"source":["---\n","**<h4>Question 9**: Write a function to instantiate a RandomForestClassifier and a LogisticRegression using scikit learn.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use `RandomForestClassifier()` to instantiate a random forest model.\n","\n","- Use `LogisticRegression()` to instantiate a logistic regression model.\n","\n","- Use `random_state` equal to **0** for both the models.\n","\n","- Put both the models in a list and return the list.\n","\n","</details>\n"]},{"cell_type":"code","metadata":{"id":"miwY5F7ttBbj"},"source":["def models_initialize():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svqtFmW-0uQf"},"source":["models_initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fgTTHJHP04eT"},"source":["---\n","**<h4>Question 10**: Fit and evaluate the models and calculate the time taken by each classifier to fit.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- `Fit` both the models on training set.\n","\n","- `Predict` the values on the train set and the test set.\n","\n","- Evaluate them using the `accuracy_score` on the train set and the test set.\n","\n","</details>\n"]},{"cell_type":"code","metadata":{"id":"GCh5q4i6-63E"},"source":["def train_n_eval(clfs=None, X_train=None, y_train=None, X_test=None, y_test=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cC7O5hBF0v1P"},"source":["train_n_eval(clfs=None, X_train=None, y_train=None, X_test=None, y_test=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qgRQZi34PJrB"},"source":["**Observations:**"]},{"cell_type":"markdown","metadata":{"id":"T_cnb0roCn7h"},"source":["<a name = Section82></a>\n","\n","### **8.2 Dimensionality Reduction using PCA**\n","\n","- In this section, we will reduce the train and test set using Principal Component Analysis."]},{"cell_type":"markdown","metadata":{"id":"2vDSFtbKgRiV"},"source":["---\n","**<h4>Question 11**: Create a function that applies PCA to fit X and plot the variation of 95% of explained variance with number of features.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Instantiate PCA using `PCA()`\n","\n","- Use `random_state` = **0** and keep `n_components` = 0.95 in the PCA model.\n","\n","- Fit the PCA model on X_train dataframe.\n","\n","- Use `np.cumsum()` to calculate the **total variance** over the different number of principal components.\n","\n","- Plot the **variance** against the **number of principal components**.\n","\n","- Look at the plot and try to figure out the value of **number of principal components** explaining **95%** of variance.\n","\n","</details>\n"]},{"cell_type":"code","metadata":{"id":"H5tf9_6HgRiV"},"source":["def apply_pca():\n","    # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yzbOjVbZLsu2"},"source":["**Observations:**"]},{"cell_type":"markdown","metadata":{"id":"bpVpZGTQ-Fv7"},"source":["---\n","**<h4>Question 12**: Create a functioin to apply PCA on X with number of principal components = 11.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Keep `n_components` as value that explain **95% variance of data** (say 11).\n","\n","- Use `random_state` as **0** in the PCA model.\n","\n","- Fit and transform X_train using `.fit_transform()`.\n","\n","- Transform X_test using `.transform()`. \n","\n","</details>\n","\n"]},{"cell_type":"code","metadata":{"id":"LK2uKmbE6VU_"},"source":["def generate_pca(X_train=None, X_test=None):\n","    # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-X_fTW4ejGv"},"source":["<a name = Section83></a>\n","\n","### **8.3 Modelling Development & Evaluation after PCA**\n","\n","- In this section, we will develop new models using the PCA reduced train and test set."]},{"cell_type":"markdown","metadata":{"id":"KBWobNq0_wW4"},"source":["---\n","**<h4>Question 13**: Use the previously generated functions to split the train-test data, train the model, make predictions on test-set and evaluate the model.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use the previously generated functions - `models_initialize()` and `train_n_eval()` for model generation, training and evaluation on the reduced data.\n","\n","</details>\n","\n"]},{"cell_type":"code","metadata":{"id":"FU9eorb50bnk"},"source":["models_initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1j9UV1LU0q96"},"source":["train_n_eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQO28waQK7Gv"},"source":["**Observations:**"]},{"cell_type":"markdown","metadata":{"id":"8r7Y8iWaJ5s6"},"source":["<a name = Section9></a>\n","\n","---\n","# **9. Conclusion**\n","---\n","\n","- We can use the above two models to check their **performance** on some **undisclosed records**.\n","\n","- This will help us to get a **general idea** of their **real-time accuracy**.\n","\n","- The **achieved performance** then can be used to **compare** and **finalize** our model for breast cancer detection."]}]}