{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Decision Tree Assignment Problem.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPh5v0hGjlSLqcZyDBLD8ii"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YOFy-OE3F0c-"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>\n","\n","**<center><h3>Decision Tree Assignment Problem</h3></center>**"]},{"cell_type":"markdown","metadata":{"id":"geoElrUULqXM"},"source":["---\n","# **Table of Contents**\n","---\n","\n","**1.** [**Problem Statement**](#Section1)<br>\n","**2.** [**Objective**](#Section2)<br>\n","**3.** [**Installing & Importing Libraries**](#Section3)<br>\n","  - **3.1** [**Installing Libraries**](#Section31)\n","  - **3.2** [**Upgrading Libraries**](#Section32)\n","  - **3.3** [**Importing Libraries**](#Section33)\n","\n","**4.** [**Data Acquisition & Description**](#Section4)<br>\n","  - **4.1** [**Data Description**](#Section41)<br>\n","\n","**5.** [**Data Pre-processing**](#Section5)<br>\n","  - **5.1** [**Pre-Profiling Report**](#Section51)<br>\n","\n","**6.** [**Exploratory Data Analysis**](#Section6)<br>\n","**7.** [**Post Data Processing**](#Section7)<br>\n","  - **7.1** [**Feature Encoding**](#Section71)\n","  - **7.2** [**Feature Scaling**](#Section72)\n","  - **7.3** [**Data Preparation**](#Section73)\n","  \n","**8.** [**Model Development & Evaluation**](#Section8)<br>\n","**9.** [**Conclusion**](#Section9)<br>\n"]},{"cell_type":"markdown","metadata":{"id":"YHjJq99XLywk"},"source":["---\n","<a name = Section1></a>\n","# **1. Problem Statement**\n","---\n","\n","- Exploring publicly available data from __LendingClub.com__.\n","\n","- Lending Club connects people who need money __(borrowers)__ with people who have money __(investors)__.\n","\n","  - Try to create a model that will help predict people who have a profile of having a __high probability of paying back__.\n","\n","  - Lending club had a very interesting year in __2016__.\n","  \n","  - This data is from _before they even went public_."]},{"cell_type":"markdown","metadata":{"id":"CsyYFAX6Lunc"},"source":["---\n","<a name = Section2></a>\n","# **2. Objective**\n","---\n","\n","- The objective of this assignment is to classify and predict whether or not the borrower paid back their loan in full."]},{"cell_type":"markdown","metadata":{"id":"_FtD_ysnMEox"},"source":["---\n","<a name = Section3></a>\n","# **3. Installing & Importing Libraries**\n","---"]},{"cell_type":"markdown","metadata":{"id":"yqLwpfW9MGhS"},"source":["<a name = Section31></a>\n","### **3.1 Installing Libraries**"]},{"cell_type":"code","metadata":{"id":"ZLe1Ef4fFuOU"},"source":["!pip install -q datascience                                                       # Package that is required by pandas profiling\n","!pip install -q pandas-profiling  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5z7fjGTsMI7S"},"source":["<a name = Section32></a>\n","### **3.2 Upgrading Libraries**\n","\n","- **After upgrading** the libraries, you need to **restart the runtime** to make the libraries in sync. \n","\n","- Make sure not to execute the cell above (3.1) and below (3.2) again after restarting the runtime."]},{"cell_type":"code","metadata":{"id":"gWKFz2K1MIwH"},"source":["!pip install -q --upgrade pandas-profiling"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oo48nYBzMN66"},"source":["<a name = Section33></a>\n","### **3.3 Importing Libraries**"]},{"cell_type":"code","metadata":{"id":"_Rvxt5bCMIth"},"source":["#-------------------------------------------------------------------------------------------------------------------------------\n","import pandas as pd                                                               # Importing for panel data analysis\n","from pandas_profiling import ProfileReport                                        # Import Pandas Profiling (To generate Univariate Analysis) \n","pd.set_option('display.max_columns', None)                                        # Unfolding hidden features if the cardinality is high      \n","pd.set_option('display.max_colwidth', None)                                       # Unfolding the max feature width for better clearity      \n","pd.set_option('display.max_rows', None)                                           # Unfolding hidden data points if the cardinality is high\n","pd.set_option('mode.chained_assignment', None)                                    # Removing restriction over chained assignments operations\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import numpy as np                                                                # Importing package numpys (For Numerical Python)\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import matplotlib.pyplot as plt                                                   # Importing pyplot interface using matplotlib\n","import seaborn as sns                                                             # Importing seaborm library for interactive visualization\n","%matplotlib inline\n","#-------------------------------------------------------------------------------------------------------------------------------\n","from sklearn.preprocessing import StandardScaler                                  # Importing Standard Scaler library from preprocessing\n","#-------------------------------------------------------------------------------------------------------------------------------\n","from sklearn.model_selection import train_test_split                              # To split the data in training and testing part \n","from sklearn.model_selection import cross_val_score                               # Importing cross validation score from model selection\n","#-------------------------------------------------------------------------------------------------------------------------------\n","from sklearn.tree import DecisionTreeClassifier                                   # Loading decision tree classifier from tree\n","#-------------------------------------------------------------------------------------------------------------------------------\n","from sklearn.metrics import classification_report                                 # To generate complete report of evaluation metrics\n","from sklearn.metrics import plot_confusion_matrix                                 # To plot confusion matrix\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import warnings                                                                   # Importing warning to disable runtime warnings\n","warnings.filterwarnings(\"ignore\")     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ekYgS1oMtGM"},"source":["---\n","<a name = Section4></a>\n","# **4. Data Acquisition & Description**\n","---\n","- The dataset has been provided by lending club and its description is shown below in the table.\n","\n","</br>\n","\n","| Records | Features | Dataset Size |\n","| :-- | :-- | :-- |\n","| 9578 | 14 | 733 KB | \n","\n","</br>\n","\n","|Id|Feature|Description|\n","|:--|:--|:--|\n","|01|**credit.policy**|1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.|\n","|02|**purpose**|The purpose to get the loan.|\n","|03|**int.rate**|\tThe interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). |\n","|||Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.|\n","|04|**installment**|The monthly installments owed by the borrower if the loan is funded.|\n","|05|**log.annual.inc**|The natural log of the self-reported annual income of the borrower.|\n","|06|**dti**|The debt-to-income ratio of the borrower (amount of debt divided by annual income).|\n","|07|**fico**|The FICO credit score of the borrower.|\n","|08|**days.with.cr.line**|The number of days the borrower has had a credit line.|\n","|09|**revol.bal**|The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).|\n","|10|**revol.util**|The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).|\n","|11|**inq.last.6mths**|The borrower's number of inquiries by creditors in the last 6 months.|\n","|12|**delinq.2yrs**|The number of times the borrower had been 30+ days past due on a payment in the past 2 years.|\n","|13|**pub.rec**|The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).|\n","|14|**not.fully.paid**|Whether the loan amount fully paid or not.|\n"]},{"cell_type":"code","metadata":{"id":"K-WAtc0tMIq9"},"source":["data = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-2/master/Data/loan_data.csv')\n","print('Data Shape:', data.shape)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ucDJhq89Rcia"},"source":["<a name = Section41></a>\n","### **4.1 Data Description**\n","\n","- In this section we will get **description** and **statistics** about the data."]},{"cell_type":"code","metadata":{"id":"NYHIoTKeMIlq"},"source":["data.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pEiefF8wT0em"},"source":["<a name = Section42></a>\n","### **4.2 Data Information**\n","\n"," - In this section, we will get **information about the data** and see some observations.\n"]},{"cell_type":"code","metadata":{"id":"RG46ZJvNMIi0"},"source":["data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jz-ZeVynUIGE"},"source":["<a name = Section5></a>\n","\n","---\n","# **5. Data Pre-Processing**\n","---"]},{"cell_type":"markdown","metadata":{"id":"DKAjCZF3UV7F"},"source":["<a name = Section51></a>\n","### **5.1 Pre Profiling Report**"]},{"cell_type":"code","metadata":{"id":"zRV-xLIvMIgO"},"source":["# profile = ProfileReport(df=data)\n","# profile.to_file(output_file='Pre Profiling Report.html')\n","# print('Accomplished!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvHFLuqRzdYr"},"source":["**Peforming Cleaning Operations**"]},{"cell_type":"markdown","metadata":{"id":"f6-BGLRZz7wy"},"source":["---\n","**<h4>Question 1:** Create a function that transform credit.policy and not.fully.paid to correct data type.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can use pandas .as_type() functionality to handle inconsistent data types.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"1flHc_sD0SXa"},"source":["def transCorrectType(feature=None, type=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMM2PnBlz6EB"},"source":["transCorrectType(feature='credit.policy', type=int)\n","transCorrectType(feature='not.fully.paid', type=int)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QbZ4RJLweGQM"},"source":["<a name = Section6></a>\n","\n","---\n","# **6. Exploratory Data Analysis**\n","---"]},{"cell_type":"markdown","metadata":{"id":"ALAJqj3vaUpM"},"source":["---\n","**<h4>Question 2:** Create a function that generate distribution of fico feature for each credit policy.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can plot the frequency distribution and proportion using seaborn histplot function.\n","\n","- You can use hue parameter for the credit.policy and add some cosmetics to make you graph look better.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"u6W6T_I5MIdd"},"source":["def ficoCreditPolicyDist():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGGhTemOMIay"},"source":["ficoCreditPolicyDist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fTiMZ5sbewgJ"},"source":["---\n","**<h4>Question 3:** Create a function that generate distribution of fico feature concerning not fully paid feature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can plot the frequency distribution and proportion using seaborn histplot function.\n","\n","- You can use hue parameter for the not.fully.paid feature and add some cosmetics to make you graph look better.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"jn-16mhfMIX6"},"source":["def ficoNotFullyPaidDist():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKy9UYclfE3m"},"source":["ficoNotFullyPaidDist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ssw7Jz8ZhvDC"},"source":["---\n","**<h4>Question 4:** Create a function that shows association between purpose and not fully paid feature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can plot the barplot and plot frequencies of categories using seaborn countplot function.\n","\n","- You can use hue parameter for the not.fully.paid feature and add some cosmetics to make you graph look better.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"3bXUBF4NfEwF"},"source":["def purposeNotFullyPaid():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jM4M8_pPfErx"},"source":["purposeNotFullyPaid()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Cnw23CLzNaJ"},"source":["<a name = Section7></a>\n","\n","---\n","# **7. Post Data Processing**\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"tc9ZOZrg1tiu"},"source":["<a name = Section71></a>\n","### **7.1 Feature Encoding**"]},{"cell_type":"markdown","metadata":{"id":"uw9RFP_62AWq"},"source":["---\n","**<h4>Question 5:** Create a function that performs one hot encoding over the purpose feature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can use pandas .get_dummies() functionality to achieve the asked objective.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"dDRpkdzw2P37"},"source":["def performEncoding(data=None, features=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEThHxUC2oVL"},"source":["data = performEncoding(data=data, features=['purpose'])\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QkRpcbPy4xyD"},"source":["<a name = Section72></a>\n","### **7.2 Feature Scaling**"]},{"cell_type":"markdown","metadata":{"id":"ksMwQVdy4vYh"},"source":["---\n","**<h4>Question 6:** Create a function that performs standard scaling over the following set of features.</h4>\n","\n","> int.rate, installment, log.annual.inc, dti, fico, days.with.cr.line, revol.bal, revol.util\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Initialize data as input and output form.\n","\n","- Initialize a list of features that needs to be scaled.\n","\n","- Create a function that performs standard scaling over the features and returns a scaled dataframe.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"0pO6yy4zfEol"},"source":["# Split the data into input and output\n","X = data.drop(labels=['not.fully.paid'], axis=1)\n","y = data['not.fully.paid']\n","\n","# Initialize a list of scaled features\n","scalerlabels = ['int.rate', 'installment', 'log.annual.inc', 'dti', \n","                'fico', 'days.with.cr.line', 'revol.bal', 'revol.util']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFgZD1IU6R1C"},"source":["def dataScaler(data=None, labels=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQT0kNcc7t0O"},"source":["X_scaled = dataScaler(data=data, labels=scalerlabels)\n","X_scaled.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QIUdRi8t7gol"},"source":["---\n","**<h4>Question 7:** Create a function that concat scaled dataframe and dataframe that contains features apart from scalerlabels.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can use .concat() functionality of pandas to concat features and return back the dataframe.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"W5tGzsSm9JF7"},"source":["def concatFrames():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rugDYrIBzQ2C"},"source":["final_data = concatFrames()\n","final_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otxEBnHk-27C"},"source":["<a name = Section73></a>\n","### **7.3 Data Preparation**"]},{"cell_type":"markdown","metadata":{"id":"UW0uVNY8_FWl"},"source":["---\n","**<h4>Question 8:** Create a function that prepare the data according to the following model requirements.</h4>\n","\n","- **Split** the data into **80:20** inside train_test_split.\n","\n","- Make sure to set the **random_state = 42**.\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can use .train_test_split functionality of sklearn package to achieve the objective.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"yDRKxqtj-oJg"},"source":["def data_prep(input=None, output=None):\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQYEfTCM_g1T"},"source":["X_train, X_test, y_train, y_test = data_prep(input=final_data, output=y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fdo3HdO3_7D7"},"source":["<a name = Section8></a>\n","\n","---\n","# **8. Model Development & Evaluation**\n","---\n","\n","- In this section, you will develop decision tree-based model.\n","\n","- Then **analyze the results** obtained and **make observations**.\n","\n","- For **evaluation purposes** we will **focus** on the **precision and recall score**.\n","\n","- **Remember** that we want to **generalize results** i.e. same results or error on testing data as that of training data."]},{"cell_type":"markdown","metadata":{"id":"SUCb5Z9PWrwx"},"source":["---\n","**<h4>Question 9:** Create a function that develops decision tree model and output a confusion matrix.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- To train decision tree model you can use sklearn package.\n","\n","- Plot a side by side figure of confusion matrix using some beautiful cosmetics.\n","\n","- You can use confusion_matrix function to generate a confusion maxtrix.\n","\n","- Display the results.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"R9PmVbYZXcgI"},"source":["def trainDecisionGetConfusion():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rK7Art_kAH4f"},"source":["trainDecisionGetConfusion()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VamyLhlXoKQ"},"source":["---\n","**<h4>Question 10:** Create a function that generates a classification report using the decision tree classifier developed above.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- To train decision tree model you can use sklearn package.\n","\n","- Fit the data on training data and then predict on both train set and test set.\n","\n","- Plot a side by side figure of confusion matrix using some beautiful cosmetics.\n","\n","- Display the results.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"AitMXlWJXn-R"},"source":["def getDecisionReport():\n","  # Put your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjQ13SI0ZLX-"},"source":["getDecisionReport()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FgWeMwv9bGMJ"},"source":["<a name = Section9></a>\n","\n","---\n","# **9. Conclusion**\n","---"]}]}